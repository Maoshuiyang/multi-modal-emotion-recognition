{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./data_collected.pickle', 'rb') as handle:\n",
    "    data2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('end', 8.2357), ('a', 2.5), ('emo_evo', [['neu'], ['neu'], ['neu'], ['neu']]), ('emotion', 'neu'), ('start', 6.2901), ('id', 'Ses01F_impro01_F000'), ('v', 2.5), ('d', 2.5), ('transcription', 'Excuse me.')])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[0].items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total num of sentences 4936\n"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "emotions = {'ang':0, 'exc':1, 'neu':2, 'sad':3}\n",
    "origin_target = []\n",
    "origin_id = []\n",
    "origin_data = []\n",
    "\n",
    "for i, ses_mod in enumerate(data2):\n",
    "    d[ses_mod['id']] = (ses_mod['transcription'], emotions[ses_mod['emotion']], i)\n",
    "    origin_id.append(ses_mod['id'])\n",
    "    origin_target.append(emotions[ses_mod['emotion']])\n",
    "    origin_data.append(ses_mod['transcription'])\n",
    "print('\\ntotal num of sentences', len(d.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "origin_train = origin_id[:3948]\n",
    "origin_test = origin_id[3948:]\n",
    "split_as_in_original_paper = {'train': origin_train, 'test':origin_test}\n",
    "with open('split_as_in_original_paper.pickle', 'wb') as handle:\n",
    "    pickle.dump(split_as_in_original_paper, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ses01F_impro01_F000', 'Ses01F_impro01_F001', 'Ses01F_impro01_F002', 'Ses01F_impro01_F005']\n",
      "['Ses05F_impro04_M009', 'Ses05F_impro04_M010', 'Ses05F_impro04_M011', 'Ses05F_impro04_M012']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3948"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./split_as_in_original_paper.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "    \n",
    "print(data['train'][:4])\n",
    "print(data['test'][:4])\n",
    "len(origin_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sentences in train: 3948\n",
      "number of sentences in test: 988\n"
     ]
    }
   ],
   "source": [
    "train_X = origin_data[:3948]\n",
    "train_y = origin_target[:3948]\n",
    "\n",
    "test_X = origin_data[3948:]\n",
    "test_y = origin_target[3948:]\n",
    "print('number of sentences in train:', len(train_X))\n",
    "print('number of sentences in test:', len(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class distribution in training data [0.23860182 0.19832827 0.34017224 0.22289767]\n"
     ]
    }
   ],
   "source": [
    "l = [0]*4\n",
    "for i in train_y:\n",
    "    l[i] += 1\n",
    "print('class distribution in training data', np.array(l)/sum(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2, 0, 2, 0, 0, 3, 3]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class distribution in test data [0.16295547 0.2611336  0.3694332  0.20647773]\n"
     ]
    }
   ],
   "source": [
    "l = [0]*4\n",
    "for i in test_y:\n",
    "    l[i] += 1\n",
    "print('class distribution in test data', np.array(l)/sum(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Excuse me.',\n",
       " 'Yeah.',\n",
       " 'Is there a problem?',\n",
       " \"Well what's the problem?  Let me change it.\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec for extracting text feature\n",
    "The original paper considers cocatenating each pre-trained glove word vector to produce a sentense vector. This is a straightforward approach to provide a quick and crude document-vector that can often be useful. However, Le and Mikolov https://arxiv.org/abs/1405.4053 in 2014 introduced the Paragraph Vector, which may outperforms such simple-concatenation. We use state-of-art gensim Doc2Vec class to generate the doc2vec paragraph vector. Specifically, there are two kinds of paragraph vector in that paper:\n",
    "Paragraph Vector, aka gensim Doc2Vec\n",
    "\n",
    "**Paragraph Vector - Distributed Memory (PV-DM)**<br>\n",
    "This is the Paragraph Vector model analogous to Word2Vec CBOW. The doc-vectors are obtained by training a neural network on the synthetic task of predicting a center word based an average of both context word-vectors and the full document's doc-vector.\n",
    "\n",
    "**Paragraph Vector - Distributed Bag of Words (PV-DBOW)**<br>\n",
    "This is the Paragraph Vector model analogous to Word2Vec SG. The doc-vectors are obtained by training a neural network on the synthetic task of predicting a target word just from the full document's doc-vector. (It is also common to combine this with skip-gram testing, using both the doc-vector and nearby word-vectors to predict a single target word, but only one at a time.)\n",
    "\n",
    "<img src='https://cdn-images-1.medium.com/max/1000/1*9tVCGDm-ytPydhtJWVx3Zw.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "from collections import OrderedDict\n",
    "import gensim\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['excuse', 'me'], tags=[0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = []\n",
    "all_text = train_X + test_X\n",
    "for i, line in enumerate(all_text):\n",
    "    #  tokenize text into individual words, remove punctuation, set to lowercase, etc\n",
    "    line = gensim.utils.simple_preprocess(line)\n",
    "    docs.append(gensim.models.doc2vec.TaggedDocument(line, [i]))\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of cores 32\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\"\n",
    "print('num of cores', cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow,d250,n5,mc2,t32) vocabulary scanned & state initialized\n",
      "Doc2Vec(\"alpha=0.05\",dm/m,d250,n5,w10,mc2,t32) vocabulary scanned & state initialized\n",
      "Doc2Vec(dm/c,d128,n5,w5,mc2,t32) vocabulary scanned & state initialized\n"
     ]
    }
   ],
   "source": [
    "doc2vec_models = [\n",
    "    # PV-DBOW plain\n",
    "    Doc2Vec(dm=0, vector_size=250, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=150, workers=cores),\n",
    "    # PV-DM w/ default averaging; \n",
    "    Doc2Vec(dm=1, vector_size=250, window=10, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=150, workers=cores, alpha=0.05, comment='alpha=0.05'),\n",
    "#     PV-DM w/ concatenation - big, slow\n",
    "#     window=5 (both sides) approximates paper's apparent 10-word total window size\n",
    "    Doc2Vec(dm=1, dm_concat=1, vector_size=128, window=5, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=150, workers=cores),\n",
    "]\n",
    "\n",
    "for model in doc2vec_models:\n",
    "    model.build_vocab(docs)\n",
    "    print(\"%s vocabulary scanned & state initialized\" % model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combining both PV-DM and PV-DBOW**<br>\n",
    "Le and Mikolov notes that combining a paragraph vector from Distributed Bag of Words (DBOW) and Distributed Memory (DM) improves performance. Since PV-DM has two kinds of mechanisms(averaging and concatenation), We will follow, pairing the models together for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "doc2vec_models.append(ConcatenatedDoc2Vec([doc2vec_models[0], doc2vec_models[1]])) # dbow+dm_averaging\n",
    "doc2vec_models.append(ConcatenatedDoc2Vec([doc2vec_models[0], doc2vec_models[2]])) # dbow+dm_concatenation\n",
    "\n",
    "for i in range(3):\n",
    "    doc2vec_models[i].train(docs, total_examples=len(docs), epochs=doc2vec_models[i].epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate which model provides the best features, we run a linear svm (polynomial or gausian provides worse result) on the training data and calculate cross valication accuracy. As we can see, the PV-DBOW(model 0) provides the best accuracy among the three single model. After combining PV-DM-concatenation(model 4), the accuracy improves a little bit. Thus we choose the model 4 as the final doc2vec model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0 Doc2Vec(dbow,d250,n5,mc2,t32)\n",
      "cross val accu for svm is 0.5311187690861002\n",
      "\n",
      "model 1 Doc2Vec(\"alpha=0.05\",dm/m,d250,n5,w10,mc2,t32)\n",
      "cross val accu for svm is 0.46832225415835627\n",
      "\n",
      "model 2 Doc2Vec(dm/c,d128,n5,w5,mc2,t32)\n",
      "cross val accu for svm is 0.33788345693004407\n",
      "\n",
      "model 3 Doc2Vec(dbow,d250,n5,mc2,t32)+Doc2Vec(\"alpha=0.05\",dm/m,d250,n5,w10,mc2,t32)\n",
      "cross val accu for svm is 0.5321375425018966\n",
      "\n",
      "model 4 Doc2Vec(dbow,d250,n5,mc2,t32)+Doc2Vec(dm/c,d128,n5,w5,mc2,t32)\n",
      "cross val accu for svm is 0.5387265640986316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(doc2vec_models):\n",
    "    # use only train data to do cross validation\n",
    "    num_data = len(train_X)\n",
    "    trainvecs = [model.docvecs[i] for i in range(num_data)]\n",
    "    svm = SVC(kernel='linear')\n",
    "    svm.fit(trainvecs, train_y)\n",
    "    print('model', i, model)\n",
    "    print('cross val accu for svm is', np.mean(cross_val_score(svm, trainvecs, train_y[:num_data], cv=5)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3948, 378)\n",
      "(988, 378)\n"
     ]
    }
   ],
   "source": [
    "num_train_data = len(train_X)\n",
    "docvec_train = np.array([doc2vec_models[4].docvecs[i] for i in range(num_train_data)])\n",
    "docvec_test = np.array([doc2vec_models[4].docvecs[i] for i in range(num_train_data, 4936)])\n",
    "all_docvec = np.array([doc2vec_models[4].docvecs[i] for i in range(4936)])\n",
    "print(docvec_train.shape)\n",
    "print(docvec_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5516194331983806"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(kernel='linear')\n",
    "svm.fit(docvec_train, train_y)\n",
    "svm.score(docvec_test, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add information of previous sentences\n",
    "We suspect previous sentences may help to predict the emotion of current sentence. We define a variable `time_steps` which determines the length of time series. We are going to reshape the training samples of shape ```(num_sentences, features)``` to ```(num_sentences/time_steps, time_steps, features)```. Since ```num_sentences``` may not be divisible by ```time_steps```, we duplicate number of ```needed``` samples in the beginning of the training set to the end of the training set to form a new training set of shape ```(num_sentences+needed, feature)```. After reshaped, the shape is ```((num_sentences+needed)/time_steps, time_steps, features)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers import LSTM, Input, Flatten, Embedding, Convolution1D,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_hot_train_y = np.eye(4)[train_y]\n",
    "one_hot_test_y = np.eye(4)[test_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate whether previous sentences provide useful information to the classification, we first generate a 3 layers sequential DNN. We can see it is able to achieve accuracy 61%-62%. However, With a `time_step` 16, the LSTM model generated below provides a better performance, achieving an accuracy 67%-68%, which demonstrates previous sentences contains very useful informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangluochao/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:13: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/20\n",
      "3948/3948 [==============================] - 2s 625us/step - loss: 1.1996 - acc: 0.4602 - val_loss: 1.0896 - val_acc: 0.5445\n",
      "Epoch 2/20\n",
      "3948/3948 [==============================] - 0s 76us/step - loss: 1.0222 - acc: 0.5661 - val_loss: 1.0286 - val_acc: 0.5769\n",
      "Epoch 3/20\n",
      "3948/3948 [==============================] - 0s 76us/step - loss: 0.9190 - acc: 0.6244 - val_loss: 0.9896 - val_acc: 0.5962\n",
      "Epoch 4/20\n",
      "3948/3948 [==============================] - 0s 78us/step - loss: 0.8215 - acc: 0.6748 - val_loss: 0.9824 - val_acc: 0.5982\n",
      "Epoch 5/20\n",
      "3948/3948 [==============================] - 0s 73us/step - loss: 0.7494 - acc: 0.7064 - val_loss: 0.9554 - val_acc: 0.6134\n",
      "Epoch 6/20\n",
      "3948/3948 [==============================] - 0s 75us/step - loss: 0.6598 - acc: 0.7409 - val_loss: 0.9465 - val_acc: 0.6225\n",
      "Epoch 7/20\n",
      "3948/3948 [==============================] - 0s 74us/step - loss: 0.5962 - acc: 0.7644 - val_loss: 0.9681 - val_acc: 0.6073\n",
      "Epoch 8/20\n",
      "3948/3948 [==============================] - 0s 79us/step - loss: 0.5411 - acc: 0.7888 - val_loss: 0.9585 - val_acc: 0.6285\n",
      "Epoch 9/20\n",
      "3948/3948 [==============================] - 0s 79us/step - loss: 0.4875 - acc: 0.8169 - val_loss: 1.0734 - val_acc: 0.6204\n",
      "Epoch 10/20\n",
      "3948/3948 [==============================] - 0s 79us/step - loss: 0.4483 - acc: 0.8280 - val_loss: 1.0126 - val_acc: 0.6255\n",
      "Epoch 11/20\n",
      "3948/3948 [==============================] - 0s 78us/step - loss: 0.4257 - acc: 0.8343 - val_loss: 1.0723 - val_acc: 0.6235\n",
      "Epoch 12/20\n",
      "3948/3948 [==============================] - 0s 81us/step - loss: 0.3894 - acc: 0.8463 - val_loss: 1.1438 - val_acc: 0.6063\n",
      "Epoch 13/20\n",
      "3948/3948 [==============================] - 0s 84us/step - loss: 0.3691 - acc: 0.8587 - val_loss: 1.1506 - val_acc: 0.6275\n",
      "Epoch 14/20\n",
      "3948/3948 [==============================] - 0s 83us/step - loss: 0.3271 - acc: 0.8759 - val_loss: 1.1857 - val_acc: 0.6204\n",
      "Epoch 15/20\n",
      "3948/3948 [==============================] - 0s 84us/step - loss: 0.3133 - acc: 0.8807 - val_loss: 1.2437 - val_acc: 0.6123\n",
      "Epoch 16/20\n",
      "3948/3948 [==============================] - 0s 83us/step - loss: 0.3024 - acc: 0.8837 - val_loss: 1.2426 - val_acc: 0.6245\n",
      "Epoch 17/20\n",
      "3948/3948 [==============================] - 0s 81us/step - loss: 0.2865 - acc: 0.8893 - val_loss: 1.3083 - val_acc: 0.6154\n",
      "Epoch 18/20\n",
      "3948/3948 [==============================] - 0s 84us/step - loss: 0.2839 - acc: 0.8934 - val_loss: 1.3185 - val_acc: 0.6265\n",
      "Epoch 19/20\n",
      "3948/3948 [==============================] - 0s 85us/step - loss: 0.2739 - acc: 0.8979 - val_loss: 1.3464 - val_acc: 0.6083\n",
      "Epoch 20/20\n",
      "3948/3948 [==============================] - 0s 88us/step - loss: 0.2545 - acc: 0.9015 - val_loss: 1.3459 - val_acc: 0.6215\n"
     ]
    }
   ],
   "source": [
    "# dnn model for baseline\n",
    "validation_data = (docvec_test, one_hot_test_y)\n",
    "model = Sequential()\n",
    "model.add(Dense(350))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam' ,metrics=['acc'])\n",
    "hist = model.fit(docvec_train, one_hot_train_y, validation_data=validation_data,\n",
    "                 batch_size=100, nb_epoch=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_57 (Dense)             (None, 350)               132650    \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 350)               0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 350)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 256)               89856     \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 223,534\n",
      "Trainable params: 223,534\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_58\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4936, 256)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "feature_layer = model.layers[-5]\n",
    "print(feature_layer.name)\n",
    "func = K.function([model.input, K.learning_phase()], [feature_layer.output])\n",
    "out_features = func([all_docvec, 0])[0]\n",
    "out_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./text_features_doc2vec(dnn_accu_62%)_256.txt', 'w') as f:\n",
    "    for r, row in enumerate(out_features):\n",
    "        row = [str(i) for i in row]\n",
    "        row = ' '.join(row)\n",
    "        f.write(row+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_lstm_samples(train_X, train_y, test_X, test_y, time_steps):\n",
    "    ''' reshape the training samples of shape (num_sentences, features) to (num_sentences/time_steps, time_steps, features). \n",
    "    Since num_sentences may not be divisible by time_steps, we duplicate number of needed samples in the beginning of the \n",
    "    training set to the end of the training set to form a new training set of shape (num_sentences+needed, feature). \n",
    "    After reshaped, the shape is ((num_sentences+needed)/time_steps, time_steps, features)\n",
    "    input:\n",
    "        train_X: ndarray of shape(None, features)\n",
    "        train_y: ndarray of shape(None, 1)\n",
    "        text_X: ndarray of shape(None, features)\n",
    "        test_y: ndarray of shape(None, 1)\n",
    "        time_steps: int\n",
    "    '''\n",
    "    features = train_X.shape[1]\n",
    "    if len(train_X) % time_steps == 0:\n",
    "        train_needed = 0\n",
    "    else:\n",
    "        train_needed = time_steps - (len(train_X) % time_steps)\n",
    "    train_X_reshaped = np.concatenate((train_X, train_X[:train_needed]), axis=0).reshape(-1, time_steps, features)\n",
    "    one_hot_train_y = np.eye(4)[train_y]\n",
    "    train_y_reshaped = np.concatenate((one_hot_train_y, one_hot_train_y[:train_needed]), axis=0).reshape(-1, time_steps, 4)\n",
    "    \n",
    "    if len(test_X) % time_steps == 0:\n",
    "        test_needed = 0\n",
    "    else:\n",
    "        test_needed = time_steps - (len(test_X) % time_steps)\n",
    "    test_X_reshaped = np.concatenate((test_X, test_X[:test_needed]), axis=0).reshape(-1, time_steps, features)\n",
    "    one_hot_test_y = np.eye(4)[test_y]\n",
    "    test_y_reshaped = np.concatenate((one_hot_test_y, one_hot_test_y[:test_needed]), axis=0).reshape(-1, time_steps, 4)\n",
    "    return train_X_reshaped, train_y_reshaped, test_X_reshaped, test_y_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(247, 16, 378)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangluochao/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:8: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(256, recurrent_dropout=0.2, return_sequences=True, input_shape=(16, 378), dropout=0.2)`\n",
      "/home/wangluochao/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:20: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 247 samples, validate on 62 samples\n",
      "Epoch 1/20\n",
      "247/247 [==============================] - 4s 16ms/step - loss: 1.3799 - acc: 0.2958 - val_loss: 1.3071 - val_acc: 0.3730\n",
      "Epoch 2/20\n",
      "247/247 [==============================] - 0s 1ms/step - loss: 1.2897 - acc: 0.3808 - val_loss: 1.2461 - val_acc: 0.4355\n",
      "Epoch 3/20\n",
      "247/247 [==============================] - 0s 1ms/step - loss: 1.1877 - acc: 0.4954 - val_loss: 1.1250 - val_acc: 0.5252\n",
      "Epoch 4/20\n",
      "247/247 [==============================] - 0s 1ms/step - loss: 1.0727 - acc: 0.5544 - val_loss: 1.0525 - val_acc: 0.5585\n",
      "Epoch 5/20\n",
      "247/247 [==============================] - 0s 1ms/step - loss: 1.0098 - acc: 0.5746 - val_loss: 0.9982 - val_acc: 0.5988\n",
      "Epoch 6/20\n",
      "247/247 [==============================] - 0s 1ms/step - loss: 0.9367 - acc: 0.6111 - val_loss: 0.9266 - val_acc: 0.6290\n",
      "Epoch 7/20\n",
      "247/247 [==============================] - 0s 1ms/step - loss: 0.9231 - acc: 0.6025 - val_loss: 0.9063 - val_acc: 0.6371\n",
      "Epoch 8/20\n",
      "247/247 [==============================] - 0s 1ms/step - loss: 0.8835 - acc: 0.6242 - val_loss: 0.8706 - val_acc: 0.6371\n",
      "Epoch 9/20\n",
      "247/247 [==============================] - 0s 1ms/step - loss: 0.8597 - acc: 0.6344 - val_loss: 0.8454 - val_acc: 0.6653\n",
      "Epoch 10/20\n",
      "247/247 [==============================] - 0s 1ms/step - loss: 0.8329 - acc: 0.6670 - val_loss: 0.8288 - val_acc: 0.6744\n",
      "Epoch 11/20\n",
      "247/247 [==============================] - 0s 1ms/step - loss: 0.8255 - acc: 0.6571 - val_loss: 0.8601 - val_acc: 0.6573\n",
      "Epoch 12/20\n",
      "247/247 [==============================] - 0s 1ms/step - loss: 0.7935 - acc: 0.6728 - val_loss: 0.8329 - val_acc: 0.6593\n",
      "Epoch 13/20\n",
      "247/247 [==============================] - 0s 1ms/step - loss: 0.7592 - acc: 0.6875 - val_loss: 0.8558 - val_acc: 0.6643\n",
      "Epoch 14/20\n",
      "247/247 [==============================] - 0s 1ms/step - loss: 0.7598 - acc: 0.6961 - val_loss: 0.8185 - val_acc: 0.6694\n",
      "Epoch 15/20\n",
      "247/247 [==============================] - 0s 1ms/step - loss: 0.7493 - acc: 0.7045 - val_loss: 0.8197 - val_acc: 0.6704\n",
      "Epoch 16/20\n",
      "247/247 [==============================] - 0s 1ms/step - loss: 0.7287 - acc: 0.7029 - val_loss: 0.8169 - val_acc: 0.6784\n",
      "Epoch 17/20\n",
      "247/247 [==============================] - 0s 1ms/step - loss: 0.7040 - acc: 0.7201 - val_loss: 0.8076 - val_acc: 0.6845\n",
      "Epoch 18/20\n",
      "247/247 [==============================] - 0s 1ms/step - loss: 0.6863 - acc: 0.7320 - val_loss: 0.8215 - val_acc: 0.6764\n",
      "Epoch 19/20\n",
      "247/247 [==============================] - 0s 1ms/step - loss: 0.6870 - acc: 0.7290 - val_loss: 0.8323 - val_acc: 0.6784\n",
      "Epoch 20/20\n",
      "247/247 [==============================] - 0s 1000us/step - loss: 0.6570 - acc: 0.7348 - val_loss: 0.8303 - val_acc: 0.6804\n"
     ]
    }
   ],
   "source": [
    "time_steps = 16\n",
    "features = docvec_train.shape[1]\n",
    "docvec_X_3d, docvec_y_3d, docvec_test_X_3d, docvec_test_y_3d = make_lstm_samples(docvec_train, train_y, docvec_test, test_y, time_steps)\n",
    "validation_data = (docvec_test_X_3d, docvec_test_y_3d)\n",
    "print(docvec_X_3d.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, dropout_U = 0.2, dropout_W = 0.2, input_shape=(time_steps, features), return_sequences=True))\n",
    "model.add(Dense(350))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam' ,metrics=['acc'])\n",
    "\n",
    "hist = model.fit(docvec_X_3d, docvec_y_3d, validation_data=validation_data,\n",
    "                 batch_size=100, nb_epoch=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 16, 256)           650240    \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 16, 350)           89950     \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 16, 350)           0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 16, 350)           0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 16, 256)           89856     \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 16, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 16, 256)           0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 16, 4)             1028      \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 16, 4)             0         \n",
      "=================================================================\n",
      "Total params: 831,074\n",
      "Trainable params: 831,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6811740890688259"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ = model.predict(docvec_test_X_3d)\n",
    "pred = pred_.reshape(-1, 4)[:988] # we only need the first 988 samples\n",
    "label = np.argmax(pred, axis=1)\n",
    "test_acc = np.mean(np.equal(label, test_y))\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_to_3d(data, time_steps):\n",
    "    features = data.shape[1]\n",
    "    if len(data) % time_steps == 0:\n",
    "        needed = 0\n",
    "    else:\n",
    "        needed = time_steps - (len(data) % time_steps)\n",
    "    reshaped = np.concatenate((data, data[:needed]), axis=0).reshape(-1, time_steps, features)\n",
    "    return reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_64\n"
     ]
    }
   ],
   "source": [
    "feature_layer = model.layers[-5]\n",
    "print(feature_layer.name)\n",
    "func = K.function([model.input, K.learning_phase()], [feature_layer.output])\n",
    "all_docvec_reshaped = reshape_to_3d(all_docvec, time_steps)\n",
    "out_features = func([all_docvec_reshaped, 0])[0]\n",
    "out_features = out_features.reshape(-1, 256)\n",
    "out_features = out_features[:4936]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./text_features_doc2vec(lstm_accu_67%)_256.txt', 'w') as f:\n",
    "    for r, row in enumerate(out_features):\n",
    "        row = [str(i) for i in row]\n",
    "        row = ' '.join(row)\n",
    "        f.write(row+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip thought vector for extracting text feature\n",
    "The above feature extraction throught LSTM to add previous sentences information to the current sentence is a supervised learning process. We suspect that thought unsupervised learning, we may also be able to add previous sentences information, resulting in better performance combined with supervised LSTM.<br>\n",
    "\n",
    "In the paper [Skip-Thought Vectors by Kiros et. al](https://arxiv.org/abs/1506.06726), they describe an approach which is to train an encoderdecoder model that tries to reconstruct the surrounding sentences of an encoded passage. Sentences that share semantic and syntactic properties are thus mapped to similar vector representations\n",
    "\n",
    "<img src='http://sanyam5.github.io/images/skip-thoughts/skip-overview.png'>\n",
    "\n",
    "**Skip-Thoughts model has three parts:**\n",
    "\n",
    "**Encoder Network**: Takes the sentence x(i) at index i and generates a fixed length representation z(i). This is a recurrent network (generally GRU or LSTM) that takes the words in a sentence sequentially.\n",
    "\n",
    "**Previous Decoder Network**: Takes the embedding z(i) and “tries” to generate the sentence x(i-1). This also is a recurrent network (generally GRU or LSTM) that generates the sentence sequentially.\n",
    "\n",
    "**Next Decoder Network**: Takes the embedding z(i) and “tries” to generate the sentence x(i+1). Again a recurrent network similar to the Previous Decoder Network.\n",
    "\n",
    "The end product of Skip-Thoughts is the Encoder. The Decoders are thrown away after training.\n",
    "\n",
    "To generate the skip-thoughts vectors, we follow the approach released by [ryankiros](https://github.com/ryankiros/skip-thoughts). Since it only support python2.7, we generate the skip-thought vector in another notebook and import it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 4800)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_vec = np.load('./skip-thought-4800.npy')\n",
    "st_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3948, 4800)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train_samples = 3948\n",
    "st_train = st_vec[:num_train_samples]\n",
    "st_test = st_vec[num_train_samples:]\n",
    "st_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangluochao/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:15: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/10\n",
      "3948/3948 [==============================] - 6s 2ms/step - loss: 1.2780 - acc: 0.4154 - val_loss: 1.1844 - val_acc: 0.4960\n",
      "Epoch 2/10\n",
      "3948/3948 [==============================] - 1s 166us/step - loss: 1.0713 - acc: 0.5448 - val_loss: 1.0730 - val_acc: 0.5628\n",
      "Epoch 3/10\n",
      "3948/3948 [==============================] - 1s 160us/step - loss: 0.9089 - acc: 0.6322 - val_loss: 0.9766 - val_acc: 0.6032\n",
      "Epoch 4/10\n",
      "3948/3948 [==============================] - 1s 163us/step - loss: 0.7803 - acc: 0.6963 - val_loss: 0.9447 - val_acc: 0.6053\n",
      "Epoch 5/10\n",
      "3948/3948 [==============================] - 1s 165us/step - loss: 0.6914 - acc: 0.7307 - val_loss: 0.9792 - val_acc: 0.5931\n",
      "Epoch 6/10\n",
      "3948/3948 [==============================] - 1s 164us/step - loss: 0.6106 - acc: 0.7655 - val_loss: 0.9724 - val_acc: 0.6265\n",
      "Epoch 7/10\n",
      "3948/3948 [==============================] - 1s 163us/step - loss: 0.5256 - acc: 0.7938 - val_loss: 1.0121 - val_acc: 0.6346\n",
      "Epoch 8/10\n",
      "3948/3948 [==============================] - 1s 160us/step - loss: 0.4759 - acc: 0.8217 - val_loss: 1.0193 - val_acc: 0.6103\n",
      "Epoch 9/10\n",
      "3948/3948 [==============================] - 1s 165us/step - loss: 0.4038 - acc: 0.8447 - val_loss: 1.0979 - val_acc: 0.6093\n",
      "Epoch 10/10\n",
      "3948/3948 [==============================] - 1s 162us/step - loss: 0.3546 - acc: 0.8670 - val_loss: 1.1208 - val_acc: 0.6215\n"
     ]
    }
   ],
   "source": [
    "# dnn model for baseline\n",
    "validation_data = (st_test, one_hot_test_y)\n",
    "model = Sequential()\n",
    "model.add(Dense(600))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam' ,metrics=['acc'])\n",
    "\n",
    "hist = model.fit(st_train, one_hot_train_y, validation_data=validation_data,\n",
    "                 batch_size=200, nb_epoch=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_198 (Dense)            (None, 600)               2880600   \n",
      "_________________________________________________________________\n",
      "activation_168 (Activation)  (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 256)               153856    \n",
      "_________________________________________________________________\n",
      "activation_169 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_170 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 3,035,484\n",
      "Trainable params: 3,035,484\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4936, 256)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_layer = model.layers[-5]\n",
    "print(feature_layer.name)\n",
    "func = K.function([model.input, K.learning_phase()], [feature_layer.output])\n",
    "out_features = func([st_vec, 0])[0]\n",
    "out_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./text_features_skip-thought(dnn_accu_62%)_256.txt', 'w') as f:\n",
    "    for r, row in enumerate(out_features):\n",
    "        row = [str(i) for i in row]\n",
    "        row = ' '.join(row)\n",
    "        f.write(row+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(247, 16, 4800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangluochao/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:8: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(256, recurrent_dropout=0.2, return_sequences=True, input_shape=(16, 4800), dropout=0.2)`\n",
      "/home/wangluochao/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:20: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 247 samples, validate on 62 samples\n",
      "Epoch 1/25\n",
      "247/247 [==============================] - 10s 41ms/step - loss: 1.3808 - acc: 0.2672 - val_loss: 1.3410 - val_acc: 0.3720\n",
      "Epoch 2/25\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 1.3553 - acc: 0.3451 - val_loss: 1.3146 - val_acc: 0.3972\n",
      "Epoch 3/25\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 1.2701 - acc: 0.3869 - val_loss: 1.2600 - val_acc: 0.4325\n",
      "Epoch 4/25\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 1.1879 - acc: 0.4646 - val_loss: 1.1150 - val_acc: 0.5323\n",
      "Epoch 5/25\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 1.0744 - acc: 0.5306 - val_loss: 1.0836 - val_acc: 0.5353\n",
      "Epoch 6/25\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.9988 - acc: 0.5949 - val_loss: 1.0455 - val_acc: 0.5565\n",
      "Epoch 7/25\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.9234 - acc: 0.6149 - val_loss: 1.0118 - val_acc: 0.5817\n",
      "Epoch 8/25\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.8741 - acc: 0.6475 - val_loss: 0.9477 - val_acc: 0.6179\n",
      "Epoch 9/25\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.8037 - acc: 0.6779 - val_loss: 0.8427 - val_acc: 0.6714\n",
      "Epoch 10/25\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.7431 - acc: 0.7120 - val_loss: 0.8712 - val_acc: 0.6482\n",
      "Epoch 11/25\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.7007 - acc: 0.7325 - val_loss: 0.9053 - val_acc: 0.6300\n",
      "Epoch 12/25\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.6688 - acc: 0.7477 - val_loss: 0.9165 - val_acc: 0.6300\n",
      "Epoch 13/25\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.6595 - acc: 0.7470 - val_loss: 0.8083 - val_acc: 0.6643\n",
      "Epoch 14/25\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.6005 - acc: 0.7713 - val_loss: 0.8354 - val_acc: 0.6673\n",
      "Epoch 15/25\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.6057 - acc: 0.7680 - val_loss: 0.8189 - val_acc: 0.6714\n",
      "Epoch 16/25\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.5876 - acc: 0.7733 - val_loss: 0.8569 - val_acc: 0.6744\n",
      "Epoch 17/25\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.5442 - acc: 0.8016 - val_loss: 0.8271 - val_acc: 0.6764\n",
      "Epoch 18/25\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.5249 - acc: 0.8067 - val_loss: 0.8497 - val_acc: 0.6643\n",
      "Epoch 19/25\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.5098 - acc: 0.8034 - val_loss: 0.7878 - val_acc: 0.6835\n",
      "Epoch 20/25\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.4765 - acc: 0.8206 - val_loss: 0.8461 - val_acc: 0.6673\n",
      "Epoch 21/25\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.4689 - acc: 0.8214 - val_loss: 0.8342 - val_acc: 0.6744\n",
      "Epoch 22/25\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.4180 - acc: 0.8462 - val_loss: 0.7873 - val_acc: 0.6875\n",
      "Epoch 23/25\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.4079 - acc: 0.8487 - val_loss: 0.8147 - val_acc: 0.6835\n",
      "Epoch 24/25\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.3818 - acc: 0.8591 - val_loss: 0.8328 - val_acc: 0.6885\n",
      "Epoch 25/25\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.3707 - acc: 0.8661 - val_loss: 0.7939 - val_acc: 0.7006\n"
     ]
    }
   ],
   "source": [
    "time_steps = 16\n",
    "features = st_train.shape[1]\n",
    "st_train_X_3d, st_train_y_3d, st_test_X_3d, st_test_y_3d = make_lstm_samples(st_train, train_y, st_test, test_y, time_steps)\n",
    "validation_data = (st_test_X_3d, st_test_y_3d)\n",
    "print(st_train_X_3d.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, dropout_U = 0.2, dropout_W = 0.2, input_shape=(time_steps, features), return_sequences=True))\n",
    "model.add(Dense(2000))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam' ,metrics=['acc'])\n",
    "\n",
    "hist = model.fit(st_train_X_3d, st_train_y_3d, validation_data=validation_data,\n",
    "                 batch_size=100, nb_epoch=25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_18 (LSTM)               (None, 16, 256)           5178368   \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 16, 2000)          514000    \n",
      "_________________________________________________________________\n",
      "activation_192 (Activation)  (None, 16, 2000)          0         \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 16, 2000)          0         \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 16, 256)           512256    \n",
      "_________________________________________________________________\n",
      "activation_193 (Activation)  (None, 16, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 16, 256)           0         \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 16, 4)             1028      \n",
      "_________________________________________________________________\n",
      "activation_194 (Activation)  (None, 16, 4)             0         \n",
      "=================================================================\n",
      "Total params: 6,205,652\n",
      "Trainable params: 6,205,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6993927125506073"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since we add needed samples to test_X to make it divisible by times_steps, it has more sentences than the original test set.\n",
    "# we only need to slice the first 988 samples, which is the number of sentences in the original test set.\n",
    "pred_ = model.predict(st_test_X_3d)\n",
    "pred = pred_.reshape(-1, 4)[:988] # we only need the first 988 samples\n",
    "label = np.argmax(pred, axis=1)\n",
    "test_acc = np.mean(np.equal(label, test_y))\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4936, 256)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_layer = model.layers[-5]\n",
    "print(feature_layer.name)\n",
    "func = K.function([model.input, K.learning_phase()], [feature_layer.output])\n",
    "all_st_vec_reshaped = reshape_to_3d(st_vec, time_steps)\n",
    "out_features = func([all_st_vec_reshaped, 0])[0]\n",
    "out_features = out_features.reshape(-1, 256)\n",
    "out_features = out_features[:4936]\n",
    "out_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./text_features_skip-thought(lstm_accu_69%)_256.txt', 'w') as f:\n",
    "    for r, row in enumerate(out_features):\n",
    "        row = [str(i) for i in row]\n",
    "        row = ' '.join(row)\n",
    "        f.write(row+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sent2vec for extracting text feature\n",
    "In the paper [Unsupervised Learning of Sentence Embeddings using Compositional N-Gram Features], they introduce a new model for sentence embeddings called Sent2Vec. It can be thought of as an extension of FastText and word2vec (CBOW) to sentences. The sentence embedding is defined as the average of the source word embeddings of its constituent words. This model is furthermore augmented by also learning source embeddings for not only unigrams but also n-grams of words present in each sentence, and averaging the n-gram embeddings along with the words. Since it has been shown to outperform doc2vec in a lot of situations in the paper, I plan to use it in this task.<br>\n",
    "\n",
    "To generate the sent2vec, we follow the approach released by the origin author Matteo Pagliardini (https://github.com/epfml/sent2vec). We use the pretrained model [sent2vec_wiki_unigrams](https://drive.google.com/open?id=0B6VhzidiLvjSa19uYWlLUEkzX3c) 5GB (600dim, trained on english wikipedia) released by them to generate our vectors. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 600)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentvec = np.load('sentvec-600.npy')\n",
    "sentvec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3948, 600)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train_samples = 3948\n",
    "sentvec_train = sentvec[:num_train_samples]\n",
    "sentvec_test = sentvec[num_train_samples:]\n",
    "sentvec_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangluochao/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:15: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/20\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.3189 - acc: 0.3754 - val_loss: 1.1997 - val_acc: 0.4929\n",
      "Epoch 2/20\n",
      "3948/3948 [==============================] - 0s 100us/step - loss: 1.1285 - acc: 0.5332 - val_loss: 1.0684 - val_acc: 0.5719\n",
      "Epoch 3/20\n",
      "3948/3948 [==============================] - 0s 105us/step - loss: 1.0023 - acc: 0.6013 - val_loss: 1.0349 - val_acc: 0.5931\n",
      "Epoch 4/20\n",
      "3948/3948 [==============================] - 0s 100us/step - loss: 0.8935 - acc: 0.6512 - val_loss: 0.9935 - val_acc: 0.6113\n",
      "Epoch 5/20\n",
      "3948/3948 [==============================] - 0s 92us/step - loss: 0.8078 - acc: 0.6905 - val_loss: 1.0244 - val_acc: 0.6144\n",
      "Epoch 6/20\n",
      "3948/3948 [==============================] - 0s 77us/step - loss: 0.7490 - acc: 0.7082 - val_loss: 0.9618 - val_acc: 0.6326\n",
      "Epoch 7/20\n",
      "3948/3948 [==============================] - 0s 80us/step - loss: 0.6887 - acc: 0.7465 - val_loss: 0.9660 - val_acc: 0.6275\n",
      "Epoch 8/20\n",
      "3948/3948 [==============================] - 0s 72us/step - loss: 0.6079 - acc: 0.7756 - val_loss: 0.9889 - val_acc: 0.6589\n",
      "Epoch 9/20\n",
      "3948/3948 [==============================] - 0s 73us/step - loss: 0.5473 - acc: 0.7971 - val_loss: 0.9751 - val_acc: 0.6437\n",
      "Epoch 10/20\n",
      "3948/3948 [==============================] - 0s 70us/step - loss: 0.4983 - acc: 0.8227 - val_loss: 1.0332 - val_acc: 0.6326\n",
      "Epoch 11/20\n",
      "3948/3948 [==============================] - 0s 73us/step - loss: 0.4714 - acc: 0.8371 - val_loss: 1.1389 - val_acc: 0.6194\n",
      "Epoch 12/20\n",
      "3948/3948 [==============================] - 0s 74us/step - loss: 0.4505 - acc: 0.8442 - val_loss: 1.1118 - val_acc: 0.6488\n",
      "Epoch 13/20\n",
      "3948/3948 [==============================] - 0s 77us/step - loss: 0.4374 - acc: 0.8409 - val_loss: 1.0558 - val_acc: 0.6397\n",
      "Epoch 14/20\n",
      "3948/3948 [==============================] - 0s 72us/step - loss: 0.3892 - acc: 0.8614 - val_loss: 1.1018 - val_acc: 0.6407\n",
      "Epoch 15/20\n",
      "3948/3948 [==============================] - 0s 75us/step - loss: 0.3650 - acc: 0.8693 - val_loss: 1.1504 - val_acc: 0.6306\n",
      "Epoch 16/20\n",
      "3948/3948 [==============================] - 0s 70us/step - loss: 0.3544 - acc: 0.8744 - val_loss: 1.1986 - val_acc: 0.6336\n",
      "Epoch 17/20\n",
      "3948/3948 [==============================] - 0s 77us/step - loss: 0.3285 - acc: 0.8840 - val_loss: 1.3134 - val_acc: 0.6397\n",
      "Epoch 18/20\n",
      "3948/3948 [==============================] - 0s 75us/step - loss: 0.3047 - acc: 0.8969 - val_loss: 1.2654 - val_acc: 0.6417\n",
      "Epoch 19/20\n",
      "3948/3948 [==============================] - 0s 70us/step - loss: 0.3061 - acc: 0.8984 - val_loss: 1.3130 - val_acc: 0.6528\n",
      "Epoch 20/20\n",
      "3948/3948 [==============================] - 0s 73us/step - loss: 0.2941 - acc: 0.8994 - val_loss: 1.2542 - val_acc: 0.6457\n"
     ]
    }
   ],
   "source": [
    "# dnn model for baseline\n",
    "validation_data = (sentvec_test, one_hot_test_y)\n",
    "model = Sequential()\n",
    "model.add(Dense(400))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam' ,metrics=['acc'])\n",
    "\n",
    "hist = model.fit(sentvec_train, one_hot_train_y, validation_data=validation_data,\n",
    "                 batch_size=200, nb_epoch=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_234 (Dense)            (None, 400)               240400    \n",
      "_________________________________________________________________\n",
      "activation_204 (Activation)  (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dropout_107 (Dropout)        (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, 256)               102656    \n",
      "_________________________________________________________________\n",
      "activation_205 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_108 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_236 (Dense)            (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_206 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 344,084\n",
      "Trainable params: 344,084\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4936, 256)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_layer = model.layers[-5]\n",
    "print(feature_layer.name)\n",
    "func = K.function([model.input, K.learning_phase()], [feature_layer.output])\n",
    "out_features = func([sentvec, 0])[0]\n",
    "out_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./text_features_sent2vec(dnn_accu_64%)_256.txt', 'w') as f:\n",
    "    for r, row in enumerate(out_features):\n",
    "        row = [str(i) for i in row]\n",
    "        row = ' '.join(row)\n",
    "        f.write(row+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(247, 16, 600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangluochao/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:8: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(256, recurrent_dropout=0.2, return_sequences=True, input_shape=(16, 600), dropout=0.2)`\n",
      "/home/wangluochao/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:20: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 247 samples, validate on 62 samples\n",
      "Epoch 1/40\n",
      "247/247 [==============================] - 12s 50ms/step - loss: 1.3955 - acc: 0.2589 - val_loss: 1.3760 - val_acc: 0.3821\n",
      "Epoch 2/40\n",
      "247/247 [==============================] - 0s 835us/step - loss: 1.3432 - acc: 0.3674 - val_loss: 1.2851 - val_acc: 0.3760\n",
      "Epoch 3/40\n",
      "247/247 [==============================] - 0s 837us/step - loss: 1.3072 - acc: 0.3641 - val_loss: 1.2880 - val_acc: 0.3972\n",
      "Epoch 4/40\n",
      "247/247 [==============================] - 0s 826us/step - loss: 1.2549 - acc: 0.4365 - val_loss: 1.2724 - val_acc: 0.4677\n",
      "Epoch 5/40\n",
      "247/247 [==============================] - 0s 844us/step - loss: 1.2295 - acc: 0.4641 - val_loss: 1.2709 - val_acc: 0.4113\n",
      "Epoch 6/40\n",
      "247/247 [==============================] - 0s 838us/step - loss: 1.2187 - acc: 0.4362 - val_loss: 1.1285 - val_acc: 0.5534\n",
      "Epoch 7/40\n",
      "247/247 [==============================] - 0s 890us/step - loss: 1.1493 - acc: 0.5314 - val_loss: 1.1303 - val_acc: 0.5575\n",
      "Epoch 8/40\n",
      "247/247 [==============================] - 0s 872us/step - loss: 1.1613 - acc: 0.5180 - val_loss: 1.1058 - val_acc: 0.5242\n",
      "Epoch 9/40\n",
      "247/247 [==============================] - 0s 830us/step - loss: 1.0820 - acc: 0.5382 - val_loss: 1.0944 - val_acc: 0.5192\n",
      "Epoch 10/40\n",
      "247/247 [==============================] - 0s 838us/step - loss: 1.0586 - acc: 0.5521 - val_loss: 1.0030 - val_acc: 0.5887\n",
      "Epoch 11/40\n",
      "247/247 [==============================] - 0s 904us/step - loss: 1.0375 - acc: 0.5681 - val_loss: 0.9940 - val_acc: 0.6028\n",
      "Epoch 12/40\n",
      "247/247 [==============================] - 0s 875us/step - loss: 0.9867 - acc: 0.6045 - val_loss: 1.0004 - val_acc: 0.5806\n",
      "Epoch 13/40\n",
      "247/247 [==============================] - 0s 869us/step - loss: 0.9557 - acc: 0.6083 - val_loss: 0.9886 - val_acc: 0.5837\n",
      "Epoch 14/40\n",
      "247/247 [==============================] - 0s 893us/step - loss: 0.9153 - acc: 0.6303 - val_loss: 0.9398 - val_acc: 0.6331\n",
      "Epoch 15/40\n",
      "247/247 [==============================] - 0s 848us/step - loss: 0.9067 - acc: 0.6409 - val_loss: 0.9825 - val_acc: 0.5978\n",
      "Epoch 16/40\n",
      "247/247 [==============================] - 0s 847us/step - loss: 0.8446 - acc: 0.6683 - val_loss: 0.9362 - val_acc: 0.6442\n",
      "Epoch 17/40\n",
      "247/247 [==============================] - 0s 838us/step - loss: 0.8515 - acc: 0.6685 - val_loss: 0.9479 - val_acc: 0.6391\n",
      "Epoch 18/40\n",
      "247/247 [==============================] - 0s 866us/step - loss: 0.8219 - acc: 0.6703 - val_loss: 0.9730 - val_acc: 0.6260\n",
      "Epoch 19/40\n",
      "247/247 [==============================] - 0s 827us/step - loss: 0.8013 - acc: 0.7007 - val_loss: 0.9335 - val_acc: 0.6240\n",
      "Epoch 20/40\n",
      "247/247 [==============================] - 0s 862us/step - loss: 0.8083 - acc: 0.6829 - val_loss: 0.8817 - val_acc: 0.6431\n",
      "Epoch 21/40\n",
      "247/247 [==============================] - 0s 870us/step - loss: 0.7548 - acc: 0.7103 - val_loss: 0.9110 - val_acc: 0.6280\n",
      "Epoch 22/40\n",
      "247/247 [==============================] - 0s 862us/step - loss: 0.7648 - acc: 0.7047 - val_loss: 0.8141 - val_acc: 0.6784\n",
      "Epoch 23/40\n",
      "247/247 [==============================] - 0s 851us/step - loss: 0.7326 - acc: 0.7232 - val_loss: 0.8017 - val_acc: 0.6744\n",
      "Epoch 24/40\n",
      "247/247 [==============================] - 0s 839us/step - loss: 0.7038 - acc: 0.7384 - val_loss: 0.8263 - val_acc: 0.6885\n",
      "Epoch 25/40\n",
      "247/247 [==============================] - 0s 871us/step - loss: 0.6969 - acc: 0.7293 - val_loss: 0.9477 - val_acc: 0.6250\n",
      "Epoch 26/40\n",
      "247/247 [==============================] - 0s 839us/step - loss: 0.7462 - acc: 0.7138 - val_loss: 0.8094 - val_acc: 0.6935\n",
      "Epoch 27/40\n",
      "247/247 [==============================] - 0s 823us/step - loss: 0.6738 - acc: 0.7523 - val_loss: 0.7991 - val_acc: 0.7046\n",
      "Epoch 28/40\n",
      "247/247 [==============================] - 0s 836us/step - loss: 0.6691 - acc: 0.7452 - val_loss: 0.7988 - val_acc: 0.6925\n",
      "Epoch 29/40\n",
      "247/247 [==============================] - 0s 854us/step - loss: 0.6475 - acc: 0.7546 - val_loss: 0.7919 - val_acc: 0.7107\n",
      "Epoch 30/40\n",
      "247/247 [==============================] - 0s 830us/step - loss: 0.6166 - acc: 0.7715 - val_loss: 0.8076 - val_acc: 0.6885\n",
      "Epoch 31/40\n",
      "247/247 [==============================] - 0s 875us/step - loss: 0.6525 - acc: 0.7566 - val_loss: 0.7886 - val_acc: 0.7046\n",
      "Epoch 32/40\n",
      "247/247 [==============================] - 0s 867us/step - loss: 0.6211 - acc: 0.7662 - val_loss: 0.7982 - val_acc: 0.6935\n",
      "Epoch 33/40\n",
      "247/247 [==============================] - 0s 842us/step - loss: 0.6073 - acc: 0.7728 - val_loss: 0.8147 - val_acc: 0.6825\n",
      "Epoch 34/40\n",
      "247/247 [==============================] - 0s 824us/step - loss: 0.6092 - acc: 0.7664 - val_loss: 0.7807 - val_acc: 0.7228\n",
      "Epoch 35/40\n",
      "247/247 [==============================] - 0s 830us/step - loss: 0.5775 - acc: 0.7844 - val_loss: 0.7778 - val_acc: 0.7157\n",
      "Epoch 36/40\n",
      "247/247 [==============================] - 0s 873us/step - loss: 0.5671 - acc: 0.7905 - val_loss: 0.8363 - val_acc: 0.6935\n",
      "Epoch 37/40\n",
      "247/247 [==============================] - 0s 853us/step - loss: 0.5661 - acc: 0.7892 - val_loss: 0.8248 - val_acc: 0.6825\n",
      "Epoch 38/40\n",
      "247/247 [==============================] - 0s 865us/step - loss: 0.5839 - acc: 0.7867 - val_loss: 0.8264 - val_acc: 0.7127\n",
      "Epoch 39/40\n",
      "247/247 [==============================] - 0s 840us/step - loss: 0.5753 - acc: 0.7849 - val_loss: 0.8333 - val_acc: 0.6855\n",
      "Epoch 40/40\n",
      "247/247 [==============================] - 0s 858us/step - loss: 0.5464 - acc: 0.7961 - val_loss: 0.7875 - val_acc: 0.7097\n"
     ]
    }
   ],
   "source": [
    "time_steps = 16\n",
    "features = sentvec_train.shape[1]\n",
    "sentvec_train_X_3d, sentvec_train_y_3d, sentvec_test_X_3d, sentvec_test_y_3d = make_lstm_samples(sentvec_train, train_y, sentvec_test, test_y, time_steps)\n",
    "validation_data = (sentvec_test_X_3d, sentvec_test_y_3d)\n",
    "print(sentvec_train_X_3d.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, dropout_U = 0.2, dropout_W = 0.2, input_shape=(time_steps, features), return_sequences=True))\n",
    "model.add(Dense(350))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam' ,metrics=['acc'])\n",
    "\n",
    "hist = model.fit(sentvec_train_X_3d, sentvec_train_y_3d, validation_data=validation_data,\n",
    "                 batch_size=200, nb_epoch=40, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_25 (LSTM)               (None, 16, 256)           877568    \n",
      "_________________________________________________________________\n",
      "dense_255 (Dense)            (None, 16, 350)           89950     \n",
      "_________________________________________________________________\n",
      "activation_225 (Activation)  (None, 16, 350)           0         \n",
      "_________________________________________________________________\n",
      "dropout_121 (Dropout)        (None, 16, 350)           0         \n",
      "_________________________________________________________________\n",
      "dense_256 (Dense)            (None, 16, 256)           89856     \n",
      "_________________________________________________________________\n",
      "activation_226 (Activation)  (None, 16, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_122 (Dropout)        (None, 16, 256)           0         \n",
      "_________________________________________________________________\n",
      "dense_257 (Dense)            (None, 16, 4)             1028      \n",
      "_________________________________________________________________\n",
      "activation_227 (Activation)  (None, 16, 4)             0         \n",
      "=================================================================\n",
      "Total params: 1,058,402\n",
      "Trainable params: 1,058,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7095141700404858"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since we add needed samples to test_X to make it divisible by times_steps, it has more sentences than the original test set.\n",
    "# we only need to slice the first 988 samples, which is the number of sentences in the original test set.\n",
    "pred_ = model.predict(sentvec_test_X_3d)\n",
    "pred = pred_.reshape(-1, 4)[:988] # we only need the first 988 samples\n",
    "label = np.argmax(pred, axis=1)\n",
    "test_acc = np.mean(np.equal(label, test_y))\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4936, 256)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_layer = model.layers[-5]\n",
    "print(feature_layer.name)\n",
    "func = K.function([model.input, K.learning_phase()], [feature_layer.output])\n",
    "all_sentvec_reshaped = reshape_to_3d(sentvec, time_steps)\n",
    "out_features = func([all_sentvec_reshaped, 0])[0]\n",
    "out_features = out_features.reshape(-1, 256)\n",
    "out_features = out_features[:4936]\n",
    "out_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./text_features_sent2vec(lstm_accu_70%)_256.txt', 'w') as f:\n",
    "    for r, row in enumerate(out_features):\n",
    "        row = [str(i) for i in row]\n",
    "        row = ' '.join(row)\n",
    "        f.write(row+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4936\n"
     ]
    }
   ],
   "source": [
    "with open('./text_features_doc2vec(lstm_accu_68%)_256.txt', 'r') as f:\n",
    "    data = f.readlines()\n",
    "    print(len(data))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
